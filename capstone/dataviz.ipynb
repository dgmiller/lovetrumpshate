{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import statements\n",
    "import utils as ut\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "reload(ut)\n",
    "plt.style.use('acme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tOptions\n",
      "\n",
      "            1: trump from lab computer\n",
      "\n",
      "            2: trump from linux mint\n",
      "\n",
      "            3: clean trump from lab computer\n",
      "\n",
      "            4: clean trump from linux mint\n",
      "\n",
      "\n",
      "Enter number >> 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>usr_fol</th>\n",
       "      <th>usr_n_stat</th>\n",
       "      <th>usr_fri</th>\n",
       "      <th>n_weblinks</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>n_hashtags</th>\n",
       "      <th>neu</th>\n",
       "      <th>comp</th>\n",
       "      <th>pos-neg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-11-09 01:46:28.711</th>\n",
       "      <td>1478681188711</td>\n",
       "      <td>30.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580</td>\n",
       "      <td>-0.6545</td>\n",
       "      <td>-0.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-09 01:46:29.694</th>\n",
       "      <td>1478681189694</td>\n",
       "      <td>201.0</td>\n",
       "      <td>11670.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.784</td>\n",
       "      <td>-0.4310</td>\n",
       "      <td>-0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-09 01:46:29.622</th>\n",
       "      <td>1478681189622</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>17840.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>-0.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-09 01:46:29.638</th>\n",
       "      <td>1478681189638</td>\n",
       "      <td>686.0</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663</td>\n",
       "      <td>-0.8235</td>\n",
       "      <td>-0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-09 01:46:30.684</th>\n",
       "      <td>1478681190684</td>\n",
       "      <td>232.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ts  usr_fol  usr_n_stat  usr_fri  \\\n",
       "ts                                                                     \n",
       "2016-11-09 01:46:28.711  1478681188711     30.0       626.0     53.0   \n",
       "2016-11-09 01:46:29.694  1478681189694    201.0     11670.0    175.0   \n",
       "2016-11-09 01:46:29.622  1478681189622   1587.0     17840.0    253.0   \n",
       "2016-11-09 01:46:29.638  1478681189638    686.0      1897.0   1805.0   \n",
       "2016-11-09 01:46:30.684  1478681190684    232.0        51.0    188.0   \n",
       "\n",
       "                         n_weblinks  n_mentions  n_hashtags    neu    comp  \\\n",
       "ts                                                                           \n",
       "2016-11-09 01:46:28.711           0           0           1  0.580 -0.6545   \n",
       "2016-11-09 01:46:29.694           0           0           0  0.784 -0.4310   \n",
       "2016-11-09 01:46:29.622           0           1           0  0.795 -0.5574   \n",
       "2016-11-09 01:46:29.638           0           0           0  0.663 -0.8235   \n",
       "2016-11-09 01:46:30.684           0           0           1  0.652  0.8402   \n",
       "\n",
       "                         pos-neg  \n",
       "ts                                \n",
       "2016-11-09 01:46:28.711   -0.420  \n",
       "2016-11-09 01:46:29.694   -0.216  \n",
       "2016-11-09 01:46:29.622   -0.205  \n",
       "2016-11-09 01:46:29.638   -0.337  \n",
       "2016-11-09 01:46:30.684    0.348  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c,df,T = ut.make_train_test()\n",
    "fname = ut.get_file()\n",
    "T = pd.read_csv(fname)\n",
    "T.index = pd.to_datetime(T['ts'],unit='ms') - pd.DateOffset(hours=7)\n",
    "T.tail()\n",
    "#df = pd.read_csv(\"/home/derekgm@byu.local/myacmeshare/trumpdf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e893041f48e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ms'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDateOffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhours\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.index = pd.to_datetime(df['ts'],unit='ms') - pd.DateOffset(hours=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Data with Neutral tweets and non-neutral tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(df['pos']-df['neg']).plot(kind='hist',bins=150,linewidth=0)\n",
    "plt.title(\"Tweet Valence (sentiment)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to classify tweets as having pro-Trump or anti-Trump sentiment on election night. Naturally, it is important to visualize a distribution of the valence, or sentiment, of the tweet data. Valence scores for positive, negative, and neutral sentiment were calculated. The compound Valence is a special combination of these three scores. It takes a normalized combination of the positive, negative, and neutral scores.\n",
    "\n",
    "In the above plot, you can see the sentiment for the entire data set. There is an exorbitant amount of neutral tweets in the data. For this reason we will look at the trends in our data without them. The dataframe labeled \"df\" refers to the full, unmodified data set. The dataframe labeled \"T\" is a modified data set where retweets and neutral tweets are removed. Tweets in the T dataframe only have scores that are not entirely neutral and that contain either positive sentiment or negative sentiment, but not both. For example, a tweet with positive score .5 and negative score .3 would not show up in the T dataframe. Similarly, a tweet with no positive or negative score and neutral score of 1. would not show up in the T dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T['pos-neg'].plot(kind='hist',bins=150,linewidth=0)\n",
    "plt.title(\"Tweet Valence (sentiment)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we remove the neutral tweets we more easily see a trend in the data. The valence distribution is bimodal with modes on either side of the spectrum. Note that the mode for each distribution is around .25 or -.25 respectively. We expected tweets to be very polarized in sentiment. This distribution suggests that fewer people tweet with extreme sentiment, contrary to what we thought.\n",
    "\n",
    "The following two plots show the distribution of neutral valence scores for the entire data set and the modified data set, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['neu'].plot(kind='hist',bins=150,linewidth=0)\n",
    "plt.title(\"Histogram of Neutral Valence Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T['neu'].plot(kind='hist',bins=150,linewidth=0)\n",
    "plt.title(\"Histogram of Neutral Valence Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two plots show the compound score distribution. The neutral scores are highly represented and once removed, we can see similar trends to the sentiment of the tweet, which makes sense because it is a combination of the negative, positive, and neutral parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['comp'].plot(kind='hist',bins=150,linewidth=0)\n",
    "plt.title(\"Tweet Compound Valence Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T['comp'].plot(kind='hist',bins=150,linewidth=0)\n",
    "plt.title(\"Tweet Compound Valence Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T.plot(kind='scatter',x='usr_fol',y='usr_fri',color=\"#191970\",alpha=.1,linewidth=0)\n",
    "x2 = np.linspace(-5,10000000,len(df))\n",
    "plt.plot(x2,x2,color='grey')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(10**1,10**7)\n",
    "plt.ylim(10**1,10**7)\n",
    "plt.title(\"Number of Followers and Friends per User (log-log)\")\n",
    "plt.xlabel(\"Number of Followers\")\n",
    "plt.ylabel(\"Number of Friends\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a plot that shows the number of follower and friends per user on Twitter. This shows something interesting and could lead us to think about other useful properties of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we look at valence scores over time. In order to observe trends in sentiment, we chose to look at the average of the sentiments over minute intervals. The following plots show these sentiment averages on the different days that the data was acquired. We are investigating the tweets at particular times in order to see why there is strange behaviour. For example, the average valence per minute on Oct. 26th starts out high and has a big drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dates = [\"10-19\",\"10-20\",\"10-24\",\"10-26\",\"11-01\",\"11-02\",\"11-03\",\"11-05\",\"11-06\",\"11-07\",\"11-08\",\"11-09\"]\n",
    "for d in dates:\n",
    "    d_ = \"2016-\" + d\n",
    "    T['comp'][d_].resample(\"1Min\").mean().plot(kind='line')\n",
    "    plt.title(\"Average Valence per Minute on \"+d)\n",
    "    plt.ylim(-.25,.25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we take a look at how average behaviour changes via the number of hashtags, mentions, weblinks, and retweets. All but the retweets seem to drop as we approach election day which is definitely worth noting. We would like to see that the expression of the current sentiment in a tweet took more precedence over mentions, hasthags, and weblinks in the approach to the election.\n",
    "\n",
    "The weblinks, mentions, and hashtags come from the modified data set. The retweets come from the original data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = T['n_weblinks'].resample(\"D\").mean().plot(kind='line',label=\"Weblinks\")\n",
    "T['n_mentions'].resample(\"D\").mean().plot(kind='line',label=\"Mentions\",ax=ax)\n",
    "T['n_hashtags'].resample(\"D\").mean().plot(kind='line',ax=ax,label=\"Hashtags\")\n",
    "df['RT'].resample(\"D\").mean().plot(kind='line',ax=ax,label=\"Retweets\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend(loc='lower left')\n",
    "plt.title(\"Average Numbers for Various Metadata by Day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These last plots show a comparison between the original and modified data sets. The trends are the same, usually with subtle differences in magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = df['n_weblinks'].resample(\"D\").mean().plot(kind='line',label=\"Weblinks\")\n",
    "df['n_mentions'].resample(\"D\").mean().plot(kind='line',label=\"Mentions\",ax=ax)\n",
    "df['n_hashtags'].resample(\"D\").mean().plot(kind='line',ax=ax,label=\"Hashtags\")\n",
    "df['RT'].resample(\"D\").mean().plot(kind='line',ax=ax,label=\"Retweets\")\n",
    "plt.ylim(0,2)\n",
    "plt.legend(loc='upper left')\n",
    "plt.title(\"Average Numbers for Various Metadata by Day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = df['n_weblinks'].resample(\"D\").mean().plot(kind='line',label=\"Total Data\")\n",
    "T['n_weblinks'].resample(\"D\").mean().plot(kind='line',label=\"Neutral Removed\")\n",
    "plt.ylim(0,2)\n",
    "plt.legend(loc='lower left')\n",
    "plt.title(\"Average Numbers for Weblinks by Day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = df['n_mentions'].resample(\"D\").mean().plot(kind='line',label=\"Total Data\")\n",
    "T['n_mentions'].resample(\"D\").mean().plot(kind='line',label=\"Neutral Removed\")\n",
    "plt.ylim(0,2)\n",
    "plt.legend(loc='lower left')\n",
    "plt.title(\"Average Numbers for Mentions by Day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = df['n_hashtags'].resample(\"D\").mean().plot(kind='line',label=\"Total Data\")\n",
    "T['n_hashtags'].resample(\"D\").mean().plot(kind='line',label=\"Neutral Removed\")\n",
    "plt.ylim(0,2)\n",
    "plt.legend(loc='lower left')\n",
    "plt.title(\"Average Numbers for Hashtags by Day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['outcome'][\"2016-11-01\":].resample(\"5Min\").mean().interpolate(method='spline',order=5).plot(kind='line',linewidth=2,figsize=(10,6))\n",
    "plt.ylim(-.25,.25)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
